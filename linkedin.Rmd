---
title: "tidy and clean linkedin scraped data"
author: "Nicholas Chung"
date: "10/13/2019"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(rjson)
library(tidyr)
library(dplyr)
library(jsonlite)
library(purrr)
library(janitor)
library(ggplot2)
library(reshape2)
library(plyr)
library(zoo)
library(RMariaDB)
```

```{r}
# load all JSON
filenames <- list.files("./data", pattern="*.json", full.names=TRUE) # this should give you a character vector, with each file name represented by an entry
myJSON <- lapply(filenames, function(x) fromJSON(txt = x)) # a list in which each element is one of your original JSON files
myJSON
```

```{r}
# create lists to populate with data
headline <- list()
connections <- list()
location <- list()
skills <- matrix()
for (i in myJSON) {
    headline <- append(headline, i$profile$headline)
    connections <- append(connections, i$profile$connections)
    location <- append(location, i$profile$location)
}

# unlist list objects
headline <- unlist(headline)
connections <- unlist(connections)
location <- unlist(location)

# load list objects into dataframe
tidy.agg <- data.frame(headline, connections, location)

tidy.agg
```

```{r}
# grab skills data 
skills.list = list()
for (i in myJSON ) {
    skills <- as.data.frame(as.matrix(merge(i$skills, i$profile$headline))) 
    skills.list <- rbind.fill(skills.list, skills)
}

skills.list

```



```{r}
# remove y[FALSE] column
skills.list <- subset(skills.list, select = c(title, count, y))
skills.list

```


```{r}

# update count class to numeric
skills.list$count <- as.numeric(skills.list$count)
skills.list$y <- as.character(skills.list$y)

```

```{r}
# replaced na count values, update column names 
df <- skills.list
df[is.na(df)] <- 0
colnames(df)[colnames(df)=="title"] <- "skills"
colnames(df)[colnames(df)=="y"] <- "title"


```


```{r}
# write csv and upload to our mysql database
write.csv(df, "df.csv")

```



```{r}
# the load of the data to our will be from the databse (dbGetQuery(myDb, "select * from df"))
df <- read.csv("df.csv")

```


```{r}
# There are more than 145 skills, clean to data similar to 2018 data
df <- subset(df, select = c(skills, count))
colnames(df) <- c("Skills", "Linkedin")
df

```

```{r}
# there are skills that is listed more than once. finding those
n_occur <- data.frame(table(df$Skills))
n_occur[n_occur$Freq > 1,]

```

```{r}
# we need to add the count of the duplicate skills rows 

df <- aggregate(Linkedin ~ Skills, dat=df, FUN=sum)
df


```

```{r}
# data is collected and ready to be analyzed at this point
summary(df)
str(df)

```

```{r}

#We have 1157 observations (skills) that data science roles use in linkedin
#let's see the distribution

theme_set(theme_classic())

ggplot(df, aes(x=Skills, y=Linkedin))+
  geom_bar(stat="identity", width = 0.5, fill=("tomato2"))+
             theme(axis.text.x = element_text(angle = 65, vjust=0.6))


```

```{r}
# we have way too many skills so let's only focus on the ones that has significant count

df <- filter(df, Linkedin >100)
df

```

```{r}
# we narrowed it down to 57 skills. Let's see how distribution works.

theme_set(theme_classic())

ggplot(df, aes(x=Skills, y=Linkedin))+
  geom_bar(stat="identity", width = 0.5, fill=("tomato2"))+
             theme(axis.text.x = element_text(angle = 65, vjust=0.6))



```

```{r}

# let's narrow it down further 
df <- filter(df, Linkedin > 200)
df

```



```{r}

theme_set(theme_classic())

ggplot(df, aes(x=reorder(Skills, Linkedin, fun=max), y=Linkedin))+
  geom_bar(stat="identity", width = 0.5, fill=("tomato2"))+
             theme(axis.text.x = element_text(angle = 65, vjust=0.6))


```

```{r}
# load the data in the database and look at 2018 Linkedin Data
user_name <- 'anil'
user_password <- "redy2rok"
database <- 'prj3'
host_name <- 'msds607.ckxhi71v1dqf.us-east-1.rds.amazonaws.com'

#connecting to the MySQL database

myDb <- dbConnect(RMariaDB::MariaDB(), user=user_name, password=user_password, dbname=database, host=host_name)
myDb
```


```{r}
#list of tables we have
dbListTables(myDb)

```


```{r}
# lets load 2018 Linkedin Data
skills_2018 <- dbGetQuery(myDb, "select * from ds_general_skills_clean")
skills_2018$LinkedIn <- as.numeric(skills_2018$LinkedIn) # little cleanup
skills_2018


```


```{r}
# analyze briefly to see if there are differences
theme_set(theme_classic())

ggplot(skills_2018, aes(x=reorder(Keyword, LinkedIn, fun=max),y=LinkedIn))+
  geom_bar(stat="identity", width = 0.5, fill=("tomato2"))+
             theme(axis.text.x = element_text(angle = 65, vjust=0.6))



```






